{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ssdmultibox.datasets import TrainPascalDataset, SIZE, NUM_CLASSES, device, Bboxer\n",
    "from ssdmultibox.utils import open_image\n",
    "from ssdmultibox.plotting import *\n",
    "from ssdmultibox.criterion import SSDLoss\n",
    "from ssdmultibox.models import SSDModel, vgg16_bn\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TrainPascalDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=4)\n",
    "image_ids, ims, gt_bbs, gt_cats = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SSDModel()\n",
    "\n",
    "ims, gt_bbs, gt_cats = dataset.to_device(ims, gt_bbs, gt_cats)\n",
    "\n",
    "preds = model(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5776]) torch.Size([4, 30324])\n",
      "torch.Size([4, 1444]) torch.Size([4, 7581])\n",
      "torch.Size([4, 400]) torch.Size([4, 2100])\n",
      "torch.Size([4, 100]) torch.Size([4, 525])\n",
      "torch.Size([4, 36]) torch.Size([4, 189])\n",
      "torch.Size([4, 4]) torch.Size([4, 21])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11640.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(preds)):\n",
    "    count += (preds[i][0][0].shape[1]/4)*6\n",
    "    print(preds[i][0][0].shape, preds[i][0][1].shape)\n",
    "    \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 36])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-2][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 36])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_bbs[-2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_cats[-2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20, 20, 20, 20,  6, 20, 20, 20, 20],\n",
       "        [20, 20, 20, 20, 12, 20, 20, 20, 20],\n",
       "        [14, 20, 14, 20, 14, 20,  1,  1,  1],\n",
       "        [20, 20, 20, 20,  6, 20, 20, 20, 20]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_cats[-2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9, 20])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-2][0][1].reshape(4, 9, -1)[:,:,:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 20])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-2][0][1].reshape(4, 9, -1)[:,:,:-1][0].shape # 1st item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0250, 0.0243, 0.0217, 0.0265, 0.0255, 0.0261, 0.0260, 0.0259, 0.0225],\n",
       "        grad_fn=<MaxBackward0>), tensor([ 0, 14, 15,  0, 15, 15, 11, 15, 15]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max prediction for the first item w/o the background class\n",
    "pred_cats = preds[-2][0][1].reshape(4, 9, -1)[:,:,:-1][0]\n",
    "max_conf, max_cls = pred_cats.max(1)\n",
    "max_conf, max_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0265, 0.0261, 0.0260, 0.0259, 0.0255, 0.0250, 0.0243, 0.0225, 0.0217],\n",
       "        grad_fn=<SortBackward>), tensor([3, 5, 6, 7, 4, 0, 1, 8, 2]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_conf.sort(0, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 1, 0, 0, 0, 0, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_value, _ = torch.mode(max_cls)\n",
    "gt_idx = max_cls == max_cls[0]\n",
    "gt_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0250, 0.0265], grad_fn=<TakeBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only look at class 11\n",
    "max_conf[gt_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0265, 0.0250], grad_fn=<SortBackward>), tensor([1, 0]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_max_conf, sorted_max_cls = max_conf[gt_idx].sort(0, descending=True)\n",
    "sorted_max_conf, sorted_max_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-2][0][0].reshape(4, -1, 4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0030,  0.0058,  0.0070, -0.0113],\n",
       "        [-0.0088,  0.0132,  0.0095, -0.0028],\n",
       "        [-0.0125,  0.0104,  0.0110, -0.0015],\n",
       "        [ 0.0117,  0.0132,  0.0166, -0.0126],\n",
       "        [ 0.0024,  0.0231,  0.0172, -0.0018],\n",
       "        [-0.0028,  0.0182,  0.0141,  0.0025],\n",
       "        [ 0.0074,  0.0110,  0.0208, -0.0202],\n",
       "        [ 0.0039,  0.0180,  0.0235, -0.0129],\n",
       "        [ 0.0002,  0.0162,  0.0204, -0.0097]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-2][0][0].reshape(4, -1, 4)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0030,  0.0058,  0.0070, -0.0113],\n",
       "        [ 0.0117,  0.0132,  0.0166, -0.0126]], grad_fn=<TakeBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-2][0][0].reshape(4, -1, 4)[0][gt_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_max_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0117,  0.0132,  0.0166, -0.0126], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_idx = sorted_max_cls[0]\n",
    "# gt_idx - filters by classes == 11\n",
    "# max_idx - is the max confidence prediction of that class\n",
    "bbs_pred = preds[-2][0][0].reshape(4, -1, 4)[0][gt_idx][max_idx]\n",
    "bbs_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,\n",
       " {'image_path': '/Users/alelevier/data/JPEGImages/000012.jpg',\n",
       "  'bbs': [[155, 96, 196, 174]],\n",
       "  'cats': [6]})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_id, ann = next(iter(dataset.get_annotations().items()))\n",
    "image_id, ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 500, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = open_image(ann['image_path'])\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.5045,  3.9556,  4.9946, -3.7779], grad_fn=<MulBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIZE * bbs_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.95557833,  3.50450969, -6.73350048,  2.49004245])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbs_pred_pascal = dataset.bboxer.fastai_bb_to_pascal_bb(SIZE*bbs_pred.detach().numpy())\n",
    "bbs_pred_pascal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.categories()[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resized_im = cv2.resize(im, (SIZE, SIZE))\n",
    "# ax = show_img(im)\n",
    "# draw_rect(ax, bbs_pred_pascal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5776]) torch.Size([4, 30324])\n",
      "torch.Size([4, 1444]) torch.Size([4, 7581])\n",
      "torch.Size([4, 400]) torch.Size([4, 2100])\n",
      "torch.Size([4, 100]) torch.Size([4, 525])\n",
      "torch.Size([4, 36]) torch.Size([4, 189])\n",
      "torch.Size([4, 4]) torch.Size([4, 21])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(preds)):\n",
    "    print(preds[i][0][0].shape, preds[i][0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1444, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0][0][0].reshape(4, -1, 4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1444, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0][0][0].reshape(4, -1, 4)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[5][0][0].reshape(4, -1, 4)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 4])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[4][0][0].reshape(4, -1, 4)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((\n",
    "    preds[4][0][0].reshape(4, -1, 4)[0],\n",
    "    preds[5][0][0].reshape(4, -1, 4)[0]\n",
    "), 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1940, 4])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat all feature_map bbs (but not aspect_ratio bbs) for the 1st training example\n",
    "all_bbs = torch.cat([\n",
    "    preds[i][0][0].reshape(4, -1, 4)[0] for i in range(6)\n",
    "], 0)\n",
    "\n",
    "all_bbs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat all bbs and cats for the 1st item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11640, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_fm_ar_bbs = torch.cat([\n",
    "    preds[i][j][0].reshape(4, -1, 4)[0] for j in range(6) for i in range(6)\n",
    "], 0)\n",
    "\n",
    "all_fm_ar_bbs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11640, 20])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 4\n",
    "num_classes = 21\n",
    "all_fm_ar_cats = torch.cat([\n",
    "    preds[i][j][1].reshape(bs, -1, num_classes)[:,:,:-1][0] for j in range(6) for i in range(6)\n",
    "], 0)\n",
    "\n",
    "all_fm_ar_cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nall_fm_ar_bbs - [11640, 4]\\nall_fm_ar_cats - [11640, 20] \\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "all_fm_ar_bbs - [11640, 4]\n",
    "all_fm_ar_cats - [11640, 20] \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the max prediction for \"car\", which we know is the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_path': '/Users/alelevier/data/JPEGImages/000012.jpg',\n",
       " 'bbs': [[155, 96, 196, 174]],\n",
       " 'cats': [6]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'car'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.categories()[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0590, 0.0678, 0.0559,  ..., 0.0226, 0.0261, 0.0214],\n",
       "        grad_fn=<MaxBackward0>), tensor([18, 16, 18,  ...,  5, 17, 16]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_conf, max_cls = all_fm_ar_cats.max(1)\n",
    "max_conf, max_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11640]), tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.uint8))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAR_ID = 6\n",
    "gt_idx = max_cls == CAR_ID\n",
    "gt_idx.shape, gt_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(690)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_idx.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([690]), torch.Size([690]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_max_conf, sorted_max_idx = max_conf[gt_idx].sort(dim=0)\n",
    "sorted_max_conf.shape, sorted_max_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([690, 4])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bbs filtered\n",
    "max_bbs = all_fm_ar_bbs[gt_idx]\n",
    "max_bbs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_bbs.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_max_conf.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply mask before `nms()` fund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(boxes, scores, overlap=0.5, top_k=200):\n",
    "    \"\"\"Apply non-maximum suppression at test time to avoid detecting too many\n",
    "    overlapping bounding boxes for a given object.\n",
    "    Args:\n",
    "        boxes: (tensor) The location preds for the img, Shape: [num_priors,4].\n",
    "        scores: (tensor) The class predscores for the img, Shape:[num_priors].\n",
    "        overlap: (float) The overlap thresh for suppressing unnecessary boxes.\n",
    "        top_k: (int) The Maximum number of box preds to consider.\n",
    "    Return:\n",
    "        The indices of the kept boxes with respect to num_priors.\n",
    "    \"\"\"\n",
    "\n",
    "    keep = scores.new(scores.size(0)).zero_().long()\n",
    "    if boxes.numel() == 0:\n",
    "        return keep\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    area = torch.mul(x2 - x1, y2 - y1)\n",
    "    v, idx = scores.sort(0)  # sort in ascending order\n",
    "    # I = I[v >= 0.01]\n",
    "    idx = idx[-top_k:]  # indices of the top-k largest vals\n",
    "    xx1 = boxes.new()\n",
    "    yy1 = boxes.new()\n",
    "    xx2 = boxes.new()\n",
    "    yy2 = boxes.new()\n",
    "    w = boxes.new()\n",
    "    h = boxes.new()\n",
    "\n",
    "    # keep = torch.Tensor()\n",
    "    count = 0\n",
    "    while idx.numel() > 0:\n",
    "        i = idx[-1]  # index of current largest val\n",
    "        # keep.append(i)\n",
    "        keep[count] = i\n",
    "        count += 1\n",
    "        if idx.size(0) == 1:\n",
    "            break\n",
    "        idx = idx[:-1]  # remove kept element from view\n",
    "        # load bboxes of next highest vals\n",
    "        torch.index_select(x1, 0, idx, out=xx1)\n",
    "        torch.index_select(y1, 0, idx, out=yy1)\n",
    "        torch.index_select(x2, 0, idx, out=xx2)\n",
    "        torch.index_select(y2, 0, idx, out=yy2)\n",
    "        # store element-wise max with next highest score\n",
    "        xx1 = torch.clamp(xx1, min=x1[i])\n",
    "        yy1 = torch.clamp(yy1, min=y1[i])\n",
    "        xx2 = torch.clamp(xx2, max=x2[i])\n",
    "        yy2 = torch.clamp(yy2, max=y2[i])\n",
    "        w.resize_as_(xx2)\n",
    "        h.resize_as_(yy2)\n",
    "        w = xx2 - xx1\n",
    "        h = yy2 - yy1\n",
    "        # check sizes of xx1 and xx2.. after each iteration\n",
    "        w = torch.clamp(w, min=0.0)\n",
    "        h = torch.clamp(h, min=0.0)\n",
    "        inter = w*h\n",
    "        # IoU = i / (area(a) + area(b) - i)\n",
    "        rem_areas = torch.index_select(area, 0, idx)  # load remaining areas)\n",
    "        union = (rem_areas - inter) + area[i]\n",
    "        IoU = inter/union  # store result in iou\n",
    "        # keep only elements with an IoU <= overlap\n",
    "        idx = idx[IoU.le(overlap)]\n",
    "    return keep, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_thresh = 0.5\n",
    "conf_thres_mask = sorted_max_conf.gt(conf_thresh)\n",
    "sorted_max_conf[conf_thres_mask].sum().item() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses `nms()` func from below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nms_keep, nms_count = nms(max_bbs.detach(), sorted_max_conf.detach())\n",
    "# nms_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(196)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(nms_keep != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1946, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_max_conf[nms_keep[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "all_fm_ar_bbs - [11640, 4]\n",
    "all_fm_ar_cats - [11640, 20] \n",
    "\"\"\"\n",
    "cls_conf, cls_ids = all_fm_ar_cats.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0590, 0.0678, 0.0559,  ..., 0.0226, 0.0261, 0.0214],\n",
       "        grad_fn=<MaxBackward0>),\n",
       " tensor([18, 16, 18,  ...,  5, 17, 16]),\n",
       " torch.Size([11640]),\n",
       " torch.Size([11640]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_conf, cls_ids = all_fm_ar_cats.max(1)\n",
    "cls_conf, cls_ids, cls_conf.shape, cls_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11640])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_ids.eq(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11640]), tensor(665))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_thresh = 0.1\n",
    "cls_conf_thres_mask = cls_conf.gt(conf_thresh)\n",
    "cls_conf_thres_mask.shape, cls_conf_thres_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([18,  2, 18,  3,  5,  5,  5,  8,  8, 14]), torch.Size([665]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_ids_gt_conf_thresh = cls_ids[cls_conf_thres_mask]\n",
    "cls_ids_gt_conf_thresh[:10], cls_ids_gt_conf_thresh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1342, 0.1228, 0.1061, 0.1046, 0.1041, 0.1199, 0.1236, 0.1142, 0.1210,\n",
       "         0.1208], grad_fn=<SliceBackward>), torch.Size([665]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_conf_gt_conf_thresh = cls_conf[cls_conf_thres_mask]\n",
    "cls_conf_gt_conf_thresh[:10], cls_conf_gt_conf_thresh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([665, 4])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbs_gt_conf_thresh = all_fm_ar_bbs[cls_conf_thres_mask]\n",
    "bbs_gt_conf_thresh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([665])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_id = 0\n",
    "gt_conf_thresh_mask = cls_ids_gt_conf_thresh.eq(cls_id)\n",
    "gt_conf_thresh_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1108, 0.1089, 0.1436, 0.1206, 0.1017, 0.1119, 0.1127, 0.1081, 0.1274,\n",
       "         0.1041], grad_fn=<SliceBackward>), torch.Size([17]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cls_conf_gt_conf_thresh[gt_conf_thresh_mask]\n",
    "scores[:10], scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2, 13, 10,  8,  3])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, ids = scores.sort(0, descending=True)\n",
    "ids[:5] # should later match first 5 ids from `nms` output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 4])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes = bbs_gt_conf_thresh[gt_conf_thresh_mask]\n",
    "boxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2, 13, 10,  8,  3]), 17)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nms_ids, nms_count = nms(boxes.detach(), scores.detach())\n",
    "nms_ids[:5], nms_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 4])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes[nms_ids[:nms_count]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_ids_gt_conf_thresh[gt_conf_thresh_mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 11640, 4]), torch.Size([4, 11640, 20]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat all feature_map bbs (but not aspect_ratio bbs) for the 1st training example\n",
    "BATCH = 4\n",
    "NUM_CLASSES = 21\n",
    "\n",
    "all_fm_ar_bbs = torch.cat([\n",
    "    preds[i][j][0].reshape(BATCH, -1, 4) for j in range(6) for i in range(6)\n",
    "], dim=1)\n",
    "\n",
    "all_fm_ar_cats = torch.cat([\n",
    "    preds[i][j][1].reshape(BATCH, -1, NUM_CLASSES)[:,:,:-1] for j in range(6) for i in range(6)\n",
    "], dim=1)\n",
    "\n",
    "all_fm_ar_bbs.detach_()\n",
    "all_fm_ar_cats.detach_()\n",
    "\n",
    "all_fm_ar_bbs.shape, all_fm_ar_cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0324, -0.0539,  0.0161, -0.0278],\n",
       "         [ 0.0338,  0.0120,  0.0419, -0.0500],\n",
       "         [ 0.0057,  0.0109, -0.0108,  0.0027]]),\n",
       " tensor([0, 0, 0]),\n",
       " torch.Size([17, 4]),\n",
       " torch.Size([17]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will change p/ cls\n",
    "cls_id = 0\n",
    "# global\n",
    "CONF_THRESH = 0.1\n",
    "# per item\n",
    "item_cats = all_fm_ar_cats[0]\n",
    "item_bbs = all_fm_ar_bbs[0]\n",
    "\n",
    "def single_predict(cls_id, item_cats, item_bbs):\n",
    "    cls_conf, cls_ids = item_cats.max(1)\n",
    "    # per cls\n",
    "    cls_conf_thresh_mask = cls_conf.gt(CONF_THRESH)\n",
    "    cls_ids_gt_conf_thresh = cls_ids[cls_conf_thresh_mask]\n",
    "    cls_conf_gt_conf_thresh = cls_conf[cls_conf_thresh_mask]\n",
    "    bbs_gt_conf_thresh = item_bbs[cls_conf_thresh_mask]\n",
    "    gt_conf_thresh_mask = cls_ids_gt_conf_thresh.eq(cls_id)\n",
    "\n",
    "    boxes = bbs_gt_conf_thresh[gt_conf_thresh_mask]\n",
    "    scores = cls_conf_gt_conf_thresh[gt_conf_thresh_mask]\n",
    "\n",
    "    nms_ids, nms_count = nms(boxes, scores)\n",
    "    return boxes[nms_ids[:nms_count]], cls_ids_gt_conf_thresh[gt_conf_thresh_mask]\n",
    "\n",
    "detects = []\n",
    "for c in range(NUM_CLASSES):\n",
    "    detects.append(single_predict(0, item_cats, item_bbs))\n",
    "    break\n",
    "    \n",
    "assert len(detects) == 1\n",
    "ret_boxes, ret_ids = detects[0]\n",
    "\n",
    "ret_boxes[:3], ret_ids[:3], ret_boxes.shape, ret_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[155, 96, 196, 174]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann['bbs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28828829, 0.31      , 0.80747748, 0.69866667])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = open_image(ann['image_path'])\n",
    "gt_bb = Bboxer.scaled_fastai_bbs(ann['bbs'], im).squeeze(0)\n",
    "gt_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03239445, -0.05390228,  0.01612709, -0.0277919 ], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_bb = ret_boxes[0].numpy()\n",
    "max_bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "needed per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def single_bb_intersect(gt_bb, max_bb):\n",
    "    \"Returns the area of the intersection of 2 bb\"\n",
    "    wh = np.minimum(\n",
    "        np.maximum(gt_bb[:2], max_bb[:2]) - np.minimum(gt_bb[2:], max_bb[2:]), 0)\n",
    "    return wh[0] * wh[1]\n",
    "    \n",
    "single_bb_intersect(gt_bb, max_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([0., 0., 10., 10.])\n",
    "b = np.array([0., 0., 25., 25.])\n",
    "single_bb_intersect(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20179153153153148, 0.000424747)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bb_area(bbs):\n",
    "    \"Returns the bb area\"\n",
    "    return np.abs(bbs[0]-bbs[2])*np.abs(bbs[1]-bbs[3])\n",
    "\n",
    "bb_area(gt_bb), bb_area(max_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def single_bb_iou(gt_bb, max_bb):\n",
    "    i = single_bb_intersect(gt_bb, max_bb)\n",
    "    # don't forget to remove their overlapping area from the union calc!\n",
    "    u = bb_area(gt_bb) + bb_area(max_bb) - i\n",
    "    return i/u\n",
    "\n",
    "single_bb_iou(gt_bb, max_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([0., 0., 10., 10.])\n",
    "b = np.array([0., 0., 25., 25.])\n",
    "single_bb_iou(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100/625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
