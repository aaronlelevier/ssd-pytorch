{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ssdmultibox.datasets import TrainPascalDataset, SIZE, NUM_CLASSES, device, Bboxer\n",
    "from ssdmultibox.utils import open_image\n",
    "from ssdmultibox.plotting import *\n",
    "from ssdmultibox.criterion import SSDLoss\n",
    "from ssdmultibox.models import SSDModel, vgg16_bn\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TrainPascalDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=4)\n",
    "image_ids, ims, gt_bbs, gt_cats = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SSDModel()\n",
    "\n",
    "ims, gt_bbs, gt_cats = dataset.to_device(ims, gt_bbs, gt_cats)\n",
    "\n",
    "preds = model(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5776]) torch.Size([4, 30324])\n",
      "torch.Size([4, 1444]) torch.Size([4, 7581])\n",
      "torch.Size([4, 400]) torch.Size([4, 2100])\n",
      "torch.Size([4, 100]) torch.Size([4, 525])\n",
      "torch.Size([4, 36]) torch.Size([4, 189])\n",
      "torch.Size([4, 4]) torch.Size([4, 21])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11640.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(preds)):\n",
    "    count += (preds[i][0][0].shape[1]/4)*6\n",
    "    print(preds[i][0][0].shape, preds[i][0][1].shape)\n",
    "    \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 36])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-2][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 36])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_bbs[-2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_cats[-2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20, 20, 20, 20,  6, 20, 20, 20, 20],\n",
       "        [20, 20, 20, 20, 12, 20, 20, 20, 20],\n",
       "        [14, 20, 14, 20, 14, 20,  1,  1,  1],\n",
       "        [20, 20, 20, 20,  6, 20, 20, 20, 20]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_cats[-2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9, 20])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-2][0][1].reshape(4, 9, -1)[:,:,:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 20])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-2][0][1].reshape(4, 9, -1)[:,:,:-1][0].shape # 1st item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0158, 0.0171, 0.0239, 0.0141, 0.0210, 0.0212, 0.0154, 0.0200, 0.0193],\n",
       "        grad_fn=<MaxBackward0>), tensor([ 4, 16,  2, 16, 16, 16,  5, 16, 16]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max prediction for the first item w/o the background class\n",
    "pred_cats = preds[-2][0][1].reshape(4, 9, -1)[:,:,:-1][0]\n",
    "max_conf, max_cls = pred_cats.max(1)\n",
    "max_conf, max_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1853, 0.1852, 0.1754,  ..., 0.0144, 0.0141, 0.0118],\n",
       "        grad_fn=<SortBackward>),\n",
       " tensor([ 896, 1084, 1082,  ..., 1501, 1933,  651]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_conf.sort(0, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1,  ..., 0, 0, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_idx, _ = torch.mode(max_cls)\n",
    "gt_idx = max_cls == max_cls[mode_idx]\n",
    "gt_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0171, 0.0141, 0.0210, 0.0212, 0.0200, 0.0193], grad_fn=<TakeBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only look at class 11\n",
    "max_conf[gt_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0212, 0.0210, 0.0200, 0.0193, 0.0171, 0.0141], grad_fn=<SortBackward>),\n",
       " tensor([3, 2, 4, 5, 0, 1]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_max_conf, sorted_max_cls = max_conf[gt_idx].sort(0, descending=True)\n",
    "sorted_max_conf, sorted_max_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-2][0][0].reshape(4, -1, 4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0007,  0.0075,  0.0044,  0.0089],\n",
       "        [-0.0018,  0.0062,  0.0030,  0.0087],\n",
       "        [ 0.0039,  0.0128,  0.0055,  0.0097],\n",
       "        [-0.0032,  0.0015,  0.0101,  0.0016],\n",
       "        [-0.0044, -0.0002,  0.0090,  0.0010],\n",
       "        [ 0.0043,  0.0096,  0.0097,  0.0047],\n",
       "        [-0.0051,  0.0058,  0.0123, -0.0007],\n",
       "        [-0.0045,  0.0046,  0.0072,  0.0005],\n",
       "        [ 0.0053,  0.0089,  0.0077,  0.0050]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-2][0][0].reshape(4, -1, 4)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0018,  0.0062,  0.0030,  0.0087],\n",
       "        [-0.0032,  0.0015,  0.0101,  0.0016],\n",
       "        [-0.0044, -0.0002,  0.0090,  0.0010],\n",
       "        [ 0.0043,  0.0096,  0.0097,  0.0047],\n",
       "        [-0.0045,  0.0046,  0.0072,  0.0005],\n",
       "        [ 0.0053,  0.0089,  0.0077,  0.0050]], grad_fn=<TakeBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-2][0][0].reshape(4, -1, 4)[0][gt_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 4, 5, 0, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_max_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0043, 0.0096, 0.0097, 0.0047], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_idx = sorted_max_cls[0]\n",
    "# gt_idx - filters by classes == 11\n",
    "# max_idx - is the max confidence prediction of that class\n",
    "bbs_pred = preds[-2][0][0].reshape(4, -1, 4)[0][gt_idx][max_idx]\n",
    "bbs_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,\n",
       " {'image_path': '/Users/aaron/data/VOC2007/trainval/VOCdevkit/VOC2007/JPEGImages/000012.jpg',\n",
       "  'bbs': [[155, 96, 196, 174]],\n",
       "  'cats': [6]})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_id, ann = next(iter(dataset.get_annotations().items()))\n",
    "image_id, ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 500, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = open_image(ann['image_path'])\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2878, 2.8777, 2.9160, 1.4069], grad_fn=<MulBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIZE * bbs_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.87771893,  1.28784156, -0.47085249,  2.62816334])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbs_pred_pascal = dataset.bboxer.fastai_bb_to_pascal_bb(SIZE*bbs_pred.detach().numpy())\n",
    "bbs_pred_pascal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.categories()[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resized_im = cv2.resize(im, (SIZE, SIZE))\n",
    "# ax = show_img(im)\n",
    "# draw_rect(ax, bbs_pred_pascal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5776]) torch.Size([4, 30324])\n",
      "torch.Size([4, 1444]) torch.Size([4, 7581])\n",
      "torch.Size([4, 400]) torch.Size([4, 2100])\n",
      "torch.Size([4, 100]) torch.Size([4, 525])\n",
      "torch.Size([4, 36]) torch.Size([4, 189])\n",
      "torch.Size([4, 4]) torch.Size([4, 21])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(preds)):\n",
    "    print(preds[i][0][0].shape, preds[i][0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1444, 4])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0][0][0].reshape(4, -1, 4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1444, 4])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0][0][0].reshape(4, -1, 4)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[5][0][0].reshape(4, -1, 4)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[4][0][0].reshape(4, -1, 4)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((\n",
    "    preds[4][0][0].reshape(4, -1, 4)[0],\n",
    "    preds[5][0][0].reshape(4, -1, 4)[0]\n",
    "), 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1940, 4])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat all feature_map bbs (but not aspect_ratio bbs) for the 1st training example\n",
    "all_bbs = torch.cat([\n",
    "    preds[i][0][0].reshape(4, -1, 4)[0] for i in range(6)\n",
    "], 0)\n",
    "\n",
    "all_bbs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat all bbs and cats for the 1st item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11640, 4])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_fm_ar_bbs = torch.cat([\n",
    "    preds[i][j][0].reshape(4, -1, 4)[0] for j in range(6) for i in range(6)\n",
    "], 0)\n",
    "\n",
    "all_fm_ar_bbs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11640, 20])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_fm_ar_cats = torch.cat([\n",
    "    preds[i][j][1].reshape(bs, -1, num_classes)[:,:,:-1][0] for j in range(6) for i in range(6)\n",
    "], 0)\n",
    "\n",
    "all_fm_ar_cats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the max prediction for \"car\", which we know is the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_path': '/Users/aaron/data/VOC2007/trainval/VOCdevkit/VOC2007/JPEGImages/000012.jpg',\n",
       " 'bbs': [[155, 96, 196, 174]],\n",
       " 'cats': [6]}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'car'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.categories()[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0742, 0.0908, 0.0462,  ..., 0.0251, 0.0215, 0.0199],\n",
       "        grad_fn=<MaxBackward0>), tensor([ 1, 14,  3,  ...,  8,  8, 19]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_conf, max_cls = all_fm_ar_cats.max(1)\n",
    "max_conf, max_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11640]), tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.uint8))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAR_ID = 6\n",
    "gt_idx = max_cls == CAR_ID\n",
    "gt_idx.shape, gt_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(506)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_idx.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([506]), torch.Size([506]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_max_conf, sorted_max_idx = max_conf[gt_idx].sort(dim=0)\n",
    "sorted_max_conf.shape, sorted_max_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([506, 4])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bbs filtered\n",
    "max_bbs = all_fm_ar_bbs[gt_idx]\n",
    "max_bbs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_bbs.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_max_conf.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply mask before `nms()` fund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_thresh = 0.5\n",
    "conf_thres_mask = sorted_max_conf.gt(conf_thresh)\n",
    "sorted_max_conf[conf_thres_mask].sum().item() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses `nms()` func from below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([505, 504, 503, 502, 501, 500, 499, 498, 497, 496, 495, 494, 493, 492,\n",
       "        491, 490, 489, 488, 487, 486, 485, 484, 483, 482, 481, 480, 479, 478,\n",
       "        477, 476, 475, 474, 473, 472, 471, 470, 469, 468, 467, 466, 465, 464,\n",
       "        463, 462, 461, 460, 459, 458, 457, 456, 455, 454, 453, 452, 451, 450,\n",
       "        449, 448, 447, 446, 445, 444, 443, 442, 441, 440, 439, 438, 437, 436,\n",
       "        435, 434, 433, 432, 431, 430, 429, 428, 427, 426, 425, 424, 423, 422,\n",
       "        421, 420, 419, 418, 417, 416, 415, 414, 413, 412, 411, 410, 409, 408,\n",
       "        407, 406, 405, 404, 403, 402, 401, 400, 399, 398, 397, 396, 395, 394,\n",
       "        393, 392, 391, 390, 389, 388, 387, 386, 385, 384, 383, 382, 381, 380,\n",
       "        378, 377, 376, 375, 374, 373, 372, 371, 370, 369, 368, 367, 366, 365,\n",
       "        364, 363, 362, 361, 360, 359, 358, 357, 356, 355, 354, 353, 352, 351,\n",
       "        350, 349, 348, 347, 346, 345, 344, 343, 342, 341, 340, 339, 338, 337,\n",
       "        336, 335, 334, 333, 332, 331, 330, 329, 328, 327, 326, 325, 324, 323,\n",
       "        322, 321, 320, 319, 318, 317, 316, 315, 314, 312, 311, 310, 309, 308,\n",
       "        307, 306,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nms_keep, nms_count = nms(max_bbs.detach(), sorted_max_conf.detach())\n",
    "nms_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(198)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(nms_keep != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1643, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_max_conf[505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(boxes, scores, overlap=0.5, top_k=200):\n",
    "    \"\"\"Apply non-maximum suppression at test time to avoid detecting too many\n",
    "    overlapping bounding boxes for a given object.\n",
    "    Args:\n",
    "        boxes: (tensor) The location preds for the img, Shape: [num_priors,4].\n",
    "        scores: (tensor) The class predscores for the img, Shape:[num_priors].\n",
    "        overlap: (float) The overlap thresh for suppressing unnecessary boxes.\n",
    "        top_k: (int) The Maximum number of box preds to consider.\n",
    "    Return:\n",
    "        The indices of the kept boxes with respect to num_priors.\n",
    "    \"\"\"\n",
    "\n",
    "    keep = scores.new(scores.size(0)).zero_().long()\n",
    "    if boxes.numel() == 0:\n",
    "        return keep\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    area = torch.mul(x2 - x1, y2 - y1)\n",
    "    v, idx = scores.sort(0)  # sort in ascending order\n",
    "    # I = I[v >= 0.01]\n",
    "    idx = idx[-top_k:]  # indices of the top-k largest vals\n",
    "    xx1 = boxes.new()\n",
    "    yy1 = boxes.new()\n",
    "    xx2 = boxes.new()\n",
    "    yy2 = boxes.new()\n",
    "    w = boxes.new()\n",
    "    h = boxes.new()\n",
    "\n",
    "    # keep = torch.Tensor()\n",
    "    count = 0\n",
    "    while idx.numel() > 0:\n",
    "        i = idx[-1]  # index of current largest val\n",
    "        # keep.append(i)\n",
    "        keep[count] = i\n",
    "        count += 1\n",
    "        if idx.size(0) == 1:\n",
    "            break\n",
    "        idx = idx[:-1]  # remove kept element from view\n",
    "        # load bboxes of next highest vals\n",
    "        torch.index_select(x1, 0, idx, out=xx1)\n",
    "        torch.index_select(y1, 0, idx, out=yy1)\n",
    "        torch.index_select(x2, 0, idx, out=xx2)\n",
    "        torch.index_select(y2, 0, idx, out=yy2)\n",
    "        # store element-wise max with next highest score\n",
    "        xx1 = torch.clamp(xx1, min=x1[i])\n",
    "        yy1 = torch.clamp(yy1, min=y1[i])\n",
    "        xx2 = torch.clamp(xx2, max=x2[i])\n",
    "        yy2 = torch.clamp(yy2, max=y2[i])\n",
    "        w.resize_as_(xx2)\n",
    "        h.resize_as_(yy2)\n",
    "        w = xx2 - xx1\n",
    "        h = yy2 - yy1\n",
    "        # check sizes of xx1 and xx2.. after each iteration\n",
    "        w = torch.clamp(w, min=0.0)\n",
    "        h = torch.clamp(h, min=0.0)\n",
    "        inter = w*h\n",
    "        # IoU = i / (area(a) + area(b) - i)\n",
    "        rem_areas = torch.index_select(area, 0, idx)  # load remaining areas)\n",
    "        union = (rem_areas - inter) + area[i]\n",
    "        IoU = inter/union  # store result in iou\n",
    "        # keep only elements with an IoU <= overlap\n",
    "        idx = idx[IoU.le(overlap)]\n",
    "    return keep, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9, 20])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 4\n",
    "num_classes = 21\n",
    "preds[4][0][1].reshape(bs, -1, num_classes)[:,:,:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1940, 20])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat all cats one-hot for the 1st training example\n",
    "all_cats = torch.cat([\n",
    "    preds[i][0][1].reshape(bs, -1, num_classes)[:,:,:-1][0]\n",
    "    for i in range(6)\n",
    "], 0)\n",
    "\n",
    "all_cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0742, 0.0908, 0.0462,  ..., 0.0200, 0.0193, 0.0218],\n",
       "        grad_fn=<MaxBackward0>), tensor([ 1, 14,  3,  ..., 16, 16,  4]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_conf, max_cls = all_cats.max(1)\n",
    "max_conf, max_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1940]), torch.Size([1940]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_conf.shape, max_conf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1853, 0.1852, 0.1754,  ..., 0.0144, 0.0141, 0.0118],\n",
       "        grad_fn=<SortBackward>),\n",
       " tensor([ 896, 1084, 1082,  ..., 1501, 1933,  651]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_max_conf, sorted_max_cls_idxs = max_conf.sort(0, descending=True)\n",
    "sorted_max_conf, sorted_max_cls_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(896), tensor(0.1853, grad_fn=<SelectBackward>), tensor(17))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_idx = sorted_max_cls_idxs[0]\n",
    "max_idx, max_conf[max_idx], max_cls[max_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surprisingly after 1 step, it predicted the right Category! of 6, which is a cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0561,  0.0402,  0.0091, -0.0465], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bbs[max_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[155, 96, 196, 174]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann['bbs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 500, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = open_image(ann['image_path'])\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28828829, 0.31      , 0.80747748, 0.69866667])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_bb = Bboxer().scaled_fastai_bbs(ann['bbs'], im).squeeze()\n",
    "gt_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05610389,  0.04020291,  0.00913793, -0.04651232], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_bb = all_bbs[max_idx].detach().numpy()\n",
    "max_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4,), (4,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_bb.shape, max_bb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28828829, 0.31      ])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.maximum(gt_bb[:2], max_bb[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00913793, -0.04651232])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.minimum(gt_bb[2:], max_bb[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def single_bb_intersect(gt_bb, max_bb):\n",
    "    wh = np.minimum(\n",
    "        np.maximum(gt_bb[:2], max_bb[:2]) - np.minimum(gt_bb[2:], max_bb[2:]), 0)\n",
    "    return wh[0] * wh[1]\n",
    "    \n",
    "single_bb_intersect(gt_bb, max_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28828829, 0.31      , 0.80747748, 0.69866667])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20179153153153148, 0.004072664)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bb_area(bbs):\n",
    "    return np.abs(bbs[0]-bbs[2])*np.abs(bbs[1]-bbs[3])\n",
    "\n",
    "bb_area(gt_bb), bb_area(max_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def single_bb_iou(gt_bb, max_bb):\n",
    "    i = single_bb_intersect(gt_bb, max_bb)\n",
    "    # don't forget to remove their overlapping area from the union calc!\n",
    "    u = bb_area(gt_bb) + bb_area(max_bb) - i\n",
    "    return i/u\n",
    "\n",
    "single_bb_iou(gt_bb, max_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([0., 0., 10., 10.])\n",
    "b = np.array([0., 0., 25., 25.])\n",
    "single_bb_iou(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_area(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_area(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 300, 300])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ims[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 300, 300])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 300, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = ims[0].permute(1,2,0)\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 500, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im2 = open_image(ann['image_path'])\n",
    "im2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32      , 0.51666667, 0.89666667, 1.16666667]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxer = Bboxer()\n",
    "bboxer.scaled_fastai_bbs(ann['bbs'], im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 300, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28828829, 0.31      , 0.80747748, 0.69866667]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scaled_fastai_bbs(bbs, im):\n",
    "    im_w = im.shape[1]\n",
    "    im_h = im.shape[0]\n",
    "    bbs = np.divide(bbs, [im_w, im_h, im_w, im_h])\n",
    "    return np.array([\n",
    "        bbs[:,1],\n",
    "        bbs[:,0],\n",
    "        bbs[:,3]+bbs[:,1]-(1/SIZE),\n",
    "        bbs[:,2]+bbs[:,0]-(1/SIZE)]).T\n",
    "\n",
    "fastai_bbs = scaled_fastai_bbs(np.array(ann['bbs']), im2)\n",
    "\n",
    "# array([[[0.28828829, 0.31      , 0.80747748, 0.69866667],\n",
    "fastai_bbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized_im = cv2.resize(im2, (SIZE, SIZE))\n",
    "resized_im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = show_img(resized_im)\n",
    "# b = Bboxer.fastai_bb_to_pascal_bb((fastai_bbs*SIZE).squeeze())\n",
    "# draw_rect(ax, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 86.48648649,  93.        , 242.24324324, 209.6       ])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fastai bbs\n",
    "b = (fastai_bbs*SIZE).squeeze()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 36])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-2][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 36])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bbs = preds[-2][1][0]\n",
    "pred_bbs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9, 4])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bbs.reshape(4, -1, 4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9, 4])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bbs = pred_bbs.reshape(4, -1, 4)\n",
    "pred_bbs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.28828829, 0.31      , 0.80747748, 0.69866667]]), (1, 4))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai_bbs, fastai_bbs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxer.anchor_corners(4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9, 4)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbs = fastai_bbs\n",
    "bbs_count = 9\n",
    "bbs16 = np.reshape(np.tile(bbs, bbs_count), (-1,bbs_count,4))\n",
    "bbs16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9, 4])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bbs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 4])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bbs[0].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9, 4)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bbs[0].unsqueeze(0).detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9, 4)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbs16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 9)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.moveaxis(anchor_corners, (0,1,2), (0,2,1))[:,:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 4])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bbs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 4])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_corners = pred_bbs[0].unsqueeze(0)\n",
    "anchor_corners.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 9])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bbs[0].unsqueeze(0).permute(0,2,1)[:,:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9, 2)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbs16[:,:,:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9, 2)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bbs[0].unsqueeze(0).detach().numpy()[:,:,:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9, 4)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_corners = pred_bbs[0].unsqueeze(0).detach().numpy()\n",
    "anchor_corners.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.28828829, 0.31      ],\n",
       "        [0.28828829, 0.31      ],\n",
       "        [0.28828829, 0.31      ],\n",
       "        [0.28828829, 0.31      ],\n",
       "        [0.28828829, 0.31      ],\n",
       "        [0.28828829, 0.31      ],\n",
       "        [0.28828829, 0.31      ],\n",
       "        [0.28828829, 0.31      ],\n",
       "        [0.28828829, 0.31      ]]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.maximum(\n",
    "    anchor_corners[:,:,:2],\n",
    "    bbs16[:,:,:2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00215022,  0.01950801],\n",
       "        [ 0.00425911,  0.01716721],\n",
       "        [ 0.00564119,  0.01605638],\n",
       "        [-0.00200997,  0.01785468],\n",
       "        [-0.00373605,  0.02233196],\n",
       "        [ 0.00184789,  0.01996584],\n",
       "        [ 0.00416726,  0.01177759],\n",
       "        [-0.00194897,  0.0158163 ],\n",
       "        [-0.00054314,  0.01564306]]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.minimum(\n",
    "    anchor_corners[:,:,2:],\n",
    "    bbs16[:,:,2:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.28613807, 0.29049199],\n",
       "        [0.28402918, 0.29283279],\n",
       "        [0.2826471 , 0.29394362],\n",
       "        [0.29029825, 0.29214532],\n",
       "        [0.29202434, 0.28766804],\n",
       "        [0.2864404 , 0.29003416],\n",
       "        [0.28412102, 0.29822241],\n",
       "        [0.29023726, 0.2941837 ],\n",
       "        [0.28883143, 0.29435694]]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_min = np.maximum(anchor_corners[:,:,:2], bbs16[:,:,:2]) - \\\n",
    "np.minimum(anchor_corners[:,:,2:], bbs16[:,:,2:])\n",
    "max_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai_bbs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9, 4)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbs16 = np.reshape(np.tile(fastai_bbs, bbs_count), (-1,bbs_count,4))\n",
    "bbs16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 4])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-2][0][0].reshape(4, -1, 4)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bbs = self.scaled_fastai_bbs(bbs, im)\n",
    "bbs_count = 9 #grid_size*grid_size\n",
    "bbs16 = np.reshape(np.tile(fastai_bbs, bbs_count), (-1,bbs_count,4)) # np.reshape(np.tile(bbs, bbs_count), (-1,bbs_count,4))\n",
    "anchor_corners = preds[-2][0][0].reshape(4, -1, 4)[0].detach().numpy() # self.anchor_corners(grid_size, aspect_ratio)\n",
    "intersect = np.minimum(\n",
    "    np.maximum(anchor_corners[:,:2], bbs16[:,:,:2]) - \\\n",
    "    np.minimum(anchor_corners[:,2:], bbs16[:,:,2:]), 0)\n",
    "intersect[:,:,0] * intersect[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.28828829, 0.31      , 0.80747748, 0.69866667],\n",
       "        [0.28828829, 0.31      , 0.80747748, 0.69866667],\n",
       "        [0.28828829, 0.31      , 0.80747748, 0.69866667],\n",
       "        [0.28828829, 0.31      , 0.80747748, 0.69866667],\n",
       "        [0.28828829, 0.31      , 0.80747748, 0.69866667],\n",
       "        [0.28828829, 0.31      , 0.80747748, 0.69866667],\n",
       "        [0.28828829, 0.31      , 0.80747748, 0.69866667],\n",
       "        [0.28828829, 0.31      , 0.80747748, 0.69866667],\n",
       "        [0.28828829, 0.31      , 0.80747748, 0.69866667]]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbs16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.01953707, 0.        , 0.00457765],\n",
       "       [0.        , 0.01807468, 0.        , 0.00290771],\n",
       "       [0.00529758, 0.02018872, 0.        , 0.00574783],\n",
       "       [0.        , 0.02480964, 0.        , 0.00409513],\n",
       "       [0.        , 0.02163003, 0.        , 0.00946532],\n",
       "       [0.00095571, 0.01893313, 0.        , 0.01274693],\n",
       "       [0.        , 0.02924913, 0.        , 0.0018008 ],\n",
       "       [0.        , 0.02630012, 0.        , 0.0105252 ],\n",
       "       [0.00297953, 0.02177737, 0.        , 0.01682711]], dtype=float32)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_corners = preds[-2][0][0].reshape(4, -1, 4)[0].detach().numpy()\n",
    "anchor_corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEXT check other feature map sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-154-cf8d8de7ebe8>(11)get_intersection()\n",
      "-> return intersect[:,:,0] * intersect[:,:,1]\n",
      "(Pdb) bbs.shape\n",
      "(1, 4)\n",
      "(Pdb) bbs16.shape\n",
      "(1, 16, 4)\n",
      "(Pdb) anchor_corners.shape\n",
      "(16, 4)\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 16)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_intersection(self, bbs, im, grid_size=4, aspect_ratio=(1.,1.)):\n",
    "    # returns the i part of IoU scaled [0,1]\n",
    "    bbs = self.scaled_fastai_bbs(bbs, im)\n",
    "    bbs_count = grid_size*grid_size\n",
    "    bbs16 = np.reshape(np.tile(bbs, bbs_count), (-1,bbs_count,4))\n",
    "    anchor_corners = self.anchor_corners(grid_size, aspect_ratio)\n",
    "    intersect = np.minimum(\n",
    "        np.maximum(anchor_corners[:,:2], bbs16[:,:,:2]) - \\\n",
    "        np.minimum(anchor_corners[:,2:], bbs16[:,:,2:]), 0)\n",
    "    pdb.set_trace()\n",
    "    return intersect[:,:,0] * intersect[:,:,1]\n",
    "\n",
    "Bboxer.get_intersection = get_intersection\n",
    "\n",
    "Bboxer().get_intersection(ann['bbs'], im2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,2,4) (1,9,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-6315dc027cfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0manchor_corners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_bbs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m intersect = np.minimum(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor_corners\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbs16\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     np.minimum(anchor_corners[:,2:], bbs16[:,:,2:]), 0)\n\u001b[1;32m      5\u001b[0m \u001b[0mintersect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mintersect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,2,4) (1,9,2) "
     ]
    }
   ],
   "source": [
    "anchor_corners = pred_bbs[0].unsqueeze(0).detach().numpy()\n",
    "intersect = np.minimum(\n",
    "    np.maximum(anchor_corners[:,:2], bbs16[:,:,:2]) - \\\n",
    "    np.minimum(anchor_corners[:,2:], bbs16[:,:,2:]), 0)\n",
    "intersect[:,:,0] * intersect[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9, 4)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_corners.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cel = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0034)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor([[0., 10.], [5., 0.]], dtype=torch.float)\n",
    "targets = torch.tensor([1, 0], dtype=torch.long)\n",
    "cel(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_cats[4][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20, 20, 20, 20,  6, 20, 20, 20, 20],\n",
       "        [20, 20, 20, 20, 12, 20, 20, 20, 20],\n",
       "        [14, 20, 14, 20, 14, 20,  1,  1,  1],\n",
       "        [20, 20, 20, 20,  6, 20, 20, 20, 20]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_cats[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 189])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[4][0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssdmultibox.datasets import Bboxer, NUM_CLASSES\n",
    "\n",
    "feature_map_idx = 0\n",
    "y = gt_cats[4][feature_map_idx]\n",
    "yhat = preds[4][feature_map_idx][1]\n",
    "\n",
    "batch_size = y.shape[0]\n",
    "cats_label = Bboxer.one_hot_encoding(y)[:,:,:-1]\n",
    "cats_preds = yhat.reshape(batch_size, -1, NUM_CLASSES)[:,:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_idxs = y != 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 18, 18,  8,  7,  6,  8])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_label[gt_idxs].argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 18, 18,  8,  7,  6,  8], dtype=torch.uint8)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[y != 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0357, 0.0276, 0.0304, 0.0250, 0.0358, 0.0306, 0.0304],\n",
       "        grad_fn=<MaxBackward0>), tensor([18, 18, 18,  2, 18, 18, 18]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_preds[gt_idxs].max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12]), torch.Size([12]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gt shape\n",
    "cats_preds[gt_idxs].argmax(1).shape, cats_label[gt_idxs].argmax(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 20]), torch.Size([12, 20]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_preds[gt_idxs].shape, cats_label[gt_idxs].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6943, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "F.binary_cross_entropy_with_logits(cats_preds[gt_idxs], cats_label[gt_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(29712)\n",
      "tensor(29707)\n",
      "tensor(102291)\n",
      "tensor(58764)\n",
      "tensor(28918)\n",
      "tensor(103671)\n",
      "tensor(14941)\n",
      "tensor(18761)\n",
      "tensor(20179)\n",
      "tensor(14504)\n",
      "tensor(15228)\n",
      "tensor(15165)\n",
      "tensor(4173)\n",
      "tensor(4165)\n",
      "tensor(1078)\n",
      "tensor(4031)\n",
      "tensor(5738)\n",
      "tensor(5295)\n",
      "tensor(521)\n",
      "tensor(1224)\n",
      "tensor(596)\n",
      "tensor(1428)\n",
      "tensor(1086)\n",
      "tensor(1284)\n",
      "tensor(453)\n",
      "tensor(95)\n",
      "tensor(432)\n",
      "tensor(272)\n",
      "tensor(196)\n",
      "tensor(551)\n",
      "tensor(29)\n",
      "tensor(70)\n",
      "tensor(26)\n",
      "tensor(16)\n",
      "tensor(42)\n",
      "tensor(9)\n"
     ]
    }
   ],
   "source": [
    "from ssdmultibox.datasets import Bboxer, NUM_CLASSES\n",
    "\n",
    "batch_size = 4\n",
    "for fm_idx in range(len(gt_cats)):\n",
    "    for ar_idx in range(len(gt_cats[fm_idx])):\n",
    "        y = gt_cats[fm_idx][ar_idx]\n",
    "        yhat = preds[fm_idx][ar_idx][1]\n",
    "        cats_label = Bboxer.one_hot_encoding(y)[:,:,:-1]\n",
    "        cats_preds = yhat.reshape(batch_size, -1, NUM_CLASSES)[:,:,:-1]\n",
    "        print(cats_preds.argmax())\n",
    "#         loss = F.binary_cross_entropy_with_logits(\n",
    "#             cats_preds[fm_idx][ar_idx],\n",
    "#             cats_label[fm_idx][ar_idx]\n",
    "#         )\n",
    "#         print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0110,  0.0171,  0.0216,  0.0110,  0.0149, -0.0023, -0.0193,  0.0132,\n",
       "         -0.0006,  0.0052, -0.0102, -0.0137, -0.0036, -0.0005, -0.0087, -0.0193,\n",
       "         -0.0056,  0.0157,  0.0210, -0.0135,  0.0081],\n",
       "        [-0.0110,  0.0171,  0.0216,  0.0110,  0.0149, -0.0023, -0.0193,  0.0132,\n",
       "         -0.0006,  0.0052, -0.0102, -0.0137, -0.0036, -0.0005, -0.0087, -0.0193,\n",
       "         -0.0056,  0.0157,  0.0210, -0.0135,  0.0081],\n",
       "        [-0.0110,  0.0171,  0.0216,  0.0110,  0.0149, -0.0023, -0.0193,  0.0132,\n",
       "         -0.0006,  0.0052, -0.0102, -0.0137, -0.0036, -0.0005, -0.0087, -0.0193,\n",
       "         -0.0056,  0.0157,  0.0210, -0.0135,  0.0081],\n",
       "        [-0.0110,  0.0171,  0.0216,  0.0110,  0.0149, -0.0023, -0.0193,  0.0132,\n",
       "         -0.0006,  0.0052, -0.0102, -0.0137, -0.0036, -0.0005, -0.0087, -0.0193,\n",
       "         -0.0056,  0.0157,  0.0210, -0.0135,  0.0081]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[-1][-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds[0][0][1] == preds[0][2][1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'foo': 1, 'bar': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-123a9cc6df61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssdmultibox.criterion import CatsBCELoss, BbsL1Loss, SSDLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(26.0574, grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_criterion = CatsBCELoss()\n",
    "bbs_criterion = BbsL1Loss()\n",
    "\n",
    "cats_loss = cats_criterion(gt_cats, preds)\n",
    "cats_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_criterion = SSDLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(296.)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssd_criterion._matched_gt_cats(gt_cats, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(296)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 0\n",
    "\n",
    "for fm_idx in range(len(gt_cats)):\n",
    "    for ar_idx in range(len(gt_cats[fm_idx])):\n",
    "        gt_idxs = gt_cats[fm_idx][ar_idx] != 20\n",
    "        n += gt_idxs.sum()\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.4059, grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbs_criterion(gt_bbs, gt_cats, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
