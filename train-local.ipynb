{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alelevier/Documents/github/ssd-pytorch/venv/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import math\n",
    "import pdb\n",
    "import platform\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import patches, patheffects\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from ssdmultibox import utils\n",
    "from ssdmultibox.bboxer import Bboxer, TensorBboxer\n",
    "from ssdmultibox.config import cfg\n",
    "from ssdmultibox.criterion import SSDLoss\n",
    "from ssdmultibox.datasets import PascalDataset, TrainPascalFlatDataset, device\n",
    "from ssdmultibox.models import SSDModel\n",
    "from ssdmultibox.plotting import *\n",
    "from ssdmultibox.predict import Predict\n",
    "from ssdmultibox.utils import open_image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {'total':[], 'loc':[], 'conf':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SSDModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-2\n",
    "\n",
    "criterion = SSDLoss(alpha=.2)\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=0.0005)\n",
    "current_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainPascalFlatDataset.__len__ = lambda self: 4\n",
    "\n",
    "train_dataset = TrainPascalFlatDataset()\n",
    "\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ssdmultibox.datasets.TrainPascalFlatDataset at 0x1423ef748>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': <ssdmultibox.datasets.TrainPascalFlatDataset at 0x1423ef748>,\n",
       " 'batch_size': 4,\n",
       " 'num_workers': 0,\n",
       " 'collate_fn': <function torch.utils.data.dataloader.default_collate(batch)>,\n",
       " 'pin_memory': False,\n",
       " 'drop_last': False,\n",
       " 'timeout': 0,\n",
       " 'worker_init_fn': None,\n",
       " 'sampler': <torch.utils.data.sampler.SequentialSampler at 0x142416048>,\n",
       " 'batch_sampler': <torch.utils.data.sampler.BatchSampler at 0x142416080>,\n",
       " '_DataLoader__initialized': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_WORKERS = 0\n",
    "BATCH = 4\n",
    "SHUFFLE = False\n",
    "    \n",
    "dataloader = DataLoader(train_dataset, batch_size=BATCH, shuffle=SHUFFLE, num_workers=NUM_WORKERS)\n",
    "\n",
    "vars(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2730e870372e4351bc4e1720fc788220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_loss: 112.7236 neg_hard_mining_loss: 354.0742\n",
      "n: 37.0 bbs_loss: 542.5619 cats_loss: 466.7977\n",
      "epoch: 0 step: 0 loss: 27.2800 time: 6.7151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    steps = math.ceil(len(train_dataset) / BATCH)\n",
    "    for step in tqdm_notebook(range(steps)):\n",
    "        image_ids, ims, gt_bbs, gt_cats = next(iter(dataloader))\n",
    "\n",
    "        # put data on device\n",
    "        ims, gt_bbs, gt_cats = PascalDataset.to_device(ims, gt_bbs, gt_cats)\n",
    "\n",
    "        # zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        preds = model(ims)\n",
    "        loss, loc_loss, conf_loss = criterion(preds, (gt_bbs, gt_cats))\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # stats\n",
    "        if step % 5 == 0:\n",
    "            print('epoch: {} step: {} loss: {:.4f} time: {:.4f}'.format(\n",
    "                epoch, step, loss.item(), time.time() - current_time))\n",
    "            current_time = time.time()\n",
    "            losses['total'].append(loss.item())\n",
    "            losses['loc'].append(loc_loss.item())\n",
    "            losses['conf'].append(conf_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbs_preds, cats_preds = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "cls_id = 6\n",
    "dataset = train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[100.0000, 100.0000, 200.0000, 200.0000],\n",
       "         [ 50.0000, 100.0000, 250.0000, 200.0000],\n",
       "         [100.0000, 100.0000, 300.0000, 200.0000],\n",
       "         [ 97.2954, 100.0000, 202.7046, 200.0000]]), tensor([6, 6, 6, 6]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targets\n",
    "get_targets(gt_cats, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[100.3507,  99.5252, 199.9233, 200.0656],\n",
       "         [ 49.4617, 100.4373, 249.2867, 200.1265],\n",
       "         [100.2074,  99.7542, 299.7056, 200.5531],\n",
       "         [ 97.2666, 100.0502, 203.4629, 199.5765]], grad_fn=<TakeBackward>),\n",
       " tensor([6, 6, 6, 6]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_targets(gt_cats, idx, bbs_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_anchor_bbs(dataset, image_ids, idx, gt_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_anchor_bbs(dataset, image_ids, idx, gt_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_nms_preds(dataset, image_ids, idx, preds, limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_nms_single_preds(dataset, image_ids, idx, cls_id, preds, limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
