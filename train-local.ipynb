{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alelevier/Documents/github/ssd-pytorch/venv/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import math\n",
    "import pdb\n",
    "import platform\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import patches, patheffects\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from ssdmultibox import utils\n",
    "from ssdmultibox.bboxer import Bboxer, TensorBboxer\n",
    "from ssdmultibox.config import cfg\n",
    "from ssdmultibox.criterion import SSDLoss\n",
    "from ssdmultibox.datasets import PascalDataset, TrainPascalFlatDataset, device\n",
    "from ssdmultibox.models import SSDModel\n",
    "from ssdmultibox.plotting import *\n",
    "from ssdmultibox.predict import Predict\n",
    "from ssdmultibox.utils import open_image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {'total':[], 'loc':[], 'conf':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SSDModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-2\n",
    "\n",
    "criterion = SSDLoss(alpha=.2)\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=0.0005)\n",
    "current_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH = 8\n",
    "\n",
    "TrainPascalFlatDataset.__len__ = lambda self: BATCH\n",
    "\n",
    "train_dataset = TrainPascalFlatDataset()\n",
    "\n",
    "len(train_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ssdmultibox.datasets.TrainPascalFlatDataset at 0x1644bd978>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': <ssdmultibox.datasets.TrainPascalFlatDataset at 0x1644bd978>,\n",
       " 'batch_size': 8,\n",
       " 'num_workers': 0,\n",
       " 'collate_fn': <function torch.utils.data.dataloader.default_collate(batch)>,\n",
       " 'pin_memory': False,\n",
       " 'drop_last': False,\n",
       " 'timeout': 0,\n",
       " 'worker_init_fn': None,\n",
       " 'sampler': <torch.utils.data.sampler.SequentialSampler at 0x1644bde10>,\n",
       " 'batch_sampler': <torch.utils.data.sampler.BatchSampler at 0x1644bde48>,\n",
       " '_DataLoader__initialized': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_WORKERS = 0\n",
    "SHUFFLE = False\n",
    "    \n",
    "dataloader = DataLoader(train_dataset, batch_size=BATCH, shuffle=SHUFFLE, num_workers=NUM_WORKERS)\n",
    "\n",
    "vars(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed642a227b442fa88aab33f8f7ee0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_loss: 204.2087 neg_hard_mining_loss: 642.3280\n",
      "n: 67.0 bbs_loss: 978.0898 cats_loss: 846.5367\n",
      "epoch: 0 step: 0 loss: 27.2332 time: 14.9513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    steps = math.ceil(len(train_dataset) / BATCH)\n",
    "    for step in tqdm_notebook(range(steps)):\n",
    "        image_ids, ims, gt_bbs, gt_cats = next(iter(dataloader))\n",
    "\n",
    "        # put data on device\n",
    "        ims, gt_bbs, gt_cats = PascalDataset.to_device(ims, gt_bbs, gt_cats)\n",
    "\n",
    "        # zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        preds = model(ims)\n",
    "        loss, loc_loss, conf_loss = criterion(preds, (gt_bbs, gt_cats))\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # stats\n",
    "        if step % 5 == 0:\n",
    "            print('epoch: {} step: {} loss: {:.4f} time: {:.4f}'.format(\n",
    "                epoch, step, loss.item(), time.time() - current_time))\n",
    "            current_time = time.time()\n",
    "            losses['total'].append(loss.item())\n",
    "            losses['loc'].append(loc_loss.item())\n",
    "            losses['conf'].append(conf_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbs_preds, cats_preds = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "cls_id = 6\n",
    "dataset = train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[100.0000, 100.0000, 200.0000, 200.0000],\n",
       "         [ 50.0000, 100.0000, 250.0000, 200.0000],\n",
       "         [100.0000, 100.0000, 300.0000, 200.0000],\n",
       "         [ 97.2954, 100.0000, 202.7046, 200.0000]]), tensor([6, 6, 6, 6]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targets\n",
    "get_targets(gt_cats, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[100.4239,  99.7479, 200.3274, 199.8281],\n",
       "         [ 49.5499,  99.1935, 250.1684, 200.5991],\n",
       "         [100.4956,  99.8876, 299.5807, 200.4930],\n",
       "         [ 96.9375,  99.4978, 202.0993, 199.5117]], grad_fn=<TakeBackward>),\n",
       " tensor([6, 6, 6, 6]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_targets(gt_cats, idx, bbs_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_anchor_bbs(dataset, image_ids, idx, gt_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_preds(dataset, image_ids, idx, bbs_preds, gt_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_nms_preds(dataset, image_ids, idx, preds, limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_nms_single_preds(dataset, image_ids, idx, cls_id, preds, limit=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_multiple(plot_anchor_bbs, plots=(2,2), dataset=dataset, image_ids=image_ids, gt_cats=gt_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_multiple(plot_preds, dataset=dataset, image_ids=image_ids, gt_cats=gt_cats, bbs_preds=bbs_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_multiple(plot_nms_preds, dataset=dataset, image_ids=image_ids, preds=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_multiple(plot_nms_single_preds, dataset=dataset, image_ids=image_ids, cls_id=cls_id, preds=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
